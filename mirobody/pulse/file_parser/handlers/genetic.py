import logging
from typing import Any, Dict
from mirobody.utils.i18n import t
from mirobody.utils.req_ctx import get_req_ctx
from mirobody.pulse.file_parser.handlers.base import BaseFileHandler, FileProcessingContext
from mirobody.pulse.file_parser.services.genetic_processor import process_genetic_file
import asyncio
from fastapi import UploadFile

class GeneticHandler(BaseFileHandler):
    def get_type_name(self) -> str:
        return "genetic"
        
    @staticmethod
    async def is_genetic_file(file: UploadFile) -> bool:
        """Check if file is a genetic data file"""
        try:
            if file.content_type != "text/plain":
                return False

            # Read file header to check for genetic file markers
            await file.seek(0)
            first_line = await file.read(100)
            await file.seek(0)

            if isinstance(first_line, (bytes, bytearray)):
                first_line = first_line.decode("utf-8", errors="ignore")

            return "# This data file generated by WeGene at" in first_line
        except Exception:
            return False

    # Genetic file handling is quite different:
    # 1. It uploads to OSS/S3 first, then saves to temp for background processing.
    # 2. It calculates file size differently (seek end).
    # 3. It returns immediately after spawning background task (genetic data parsing happens async).
    
    async def process(self, ctx: FileProcessingContext) -> Dict[str, Any]:
        # Override process completely because the flow is very different
        file_key = None
        try:
            language = get_req_ctx("language", "en")
            
            # Generate file_key using base class method
            file_key = self._get_unique_filename(ctx)

            # Get file size
            await ctx.file.seek(0, 2)
            file_size = ctx.file.tell()
            await ctx.file.seek(0)

            if ctx.progress_callback:
                await ctx.progress_callback(30, t("uploading_file", language, "file_processor"))

            # Upload file to OSS/S3 storage (same as other file types)
            full_url = await self._handle_upload(ctx, file_key, language)
            logging.info(f"âœ… Genetic file uploaded to storage: {file_key}, URL: {full_url}")

            if ctx.progress_callback:
                await ctx.progress_callback(40, t("genetic_file_saving", language, "load_genetic_data"))

            # Save file to temporary path for background processing
            temp_file_path, _ = await self.temp_manager.save_upload_file_to_temp(ctx.file)

            if ctx.progress_callback:
                 await ctx.progress_callback(50, t("genetic_file_processing_background", language, "load_genetic_data"))

            # Simple file abstract for genetic files (no LLM extraction needed)
            file_name = ctx.filename
            file_abstract = t("genetic_file_abstract", language, "load_genetic_data", filename=ctx.filename)

            response = {
                "success": True,
                "message": t("genetic_file_received", language, "load_genetic_data"),
                "type": "genetic",
                "filename": ctx.filename,
                "file_size": file_size,
                "url_thumb": full_url or ctx.filename,
                "full_url": full_url or ctx.filename,
                "raw": t("genetic_file_processing_background", language, "load_genetic_data"),
                "file_abstract": file_abstract,
                "file_name": file_name,
                "message_id": ctx.message_id,
                "file_key": file_key,
            }

            # Spawn background task
            asyncio.create_task(
                process_genetic_file(
                    user_id=ctx.user_id,
                    temp_file_path=str(temp_file_path),
                    message_id=ctx.message_id,
                    language=language,
                    original_filename=ctx.filename,
                    original_file_size=file_size,
                    source_table="theta_ai.th_messages",
                    source_table_id=str(ctx.message_id),
                    file_key=file_key,
                    full_url=full_url,
                    file_abstract=file_abstract,
                )
            )
            
            return response

        except Exception as e:
             return await self._handle_error(ctx, e, file_key)

    async def _process_content(self, *args, **kwargs):
        pass # Not used due to override

